{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "import time\n",
    "import pickle\n",
    "import sys\n",
    "import os\n",
    "\n",
    "sys.setrecursionlimit(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops through the years, scrapes Box Office Mojo & returns the result with True or Issue with False\n",
    "\n",
    "all_movies_html = dict()\n",
    "\n",
    "for year in range(2010,2020,1):\n",
    "    all_movies_html[year] = scrape_movie_list_opening_weekend(year)\n",
    "    time.sleep(.5+2*random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "EOFError",
     "evalue": "Ran out of input",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mEOFError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-5ab4316d7e0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Movies_list_HTML.pickle\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmovies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_from_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-354126fd11a2>\u001b[0m in \u001b[0;36mread_from_pickle\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# if file is not empty scores will be equal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# to the value unpickled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mEOFError\u001b[0m: Ran out of input"
     ]
    }
   ],
   "source": [
    "target = \"Movies_list_HTML.pickle\"\n",
    "os.path.getsize(target)\n",
    "movies = read_from_pickle(target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Individual_Scraping.ipynb  README.md\r\n",
      "Initial_Scraping.ipynb\t   Scraped_Cleaned_MoviesList_2010-19.csv\r\n",
      "Movies_list_HTML.pickle\r\n"
     ]
    }
   ],
   "source": [
    "!ls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to dataframe & save as csv\n",
    "\n",
    "# df_list = pd.concat([pd.json_normalize(all_movies_clean[year]) for year in all_movies_clean],ignore_index=True)\n",
    "\n",
    "# df_list.to_csv('Scraped_Cleaned_MoviesList_2010-19.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_movies_clean = dict()\n",
    "all_errors_clean =dict()\n",
    "\n",
    "for year in range(2010,2020,1):\n",
    "    \n",
    "    if all_movies_html[year][0]:\n",
    "\n",
    "        movies_log = list()\n",
    "        error_log = list() \n",
    "        counter = 1\n",
    "\n",
    "        for table_row in all_movies_html[year][1]:\n",
    "\n",
    "            if table_row.find('td'):\n",
    "\n",
    "                table_row_data = table_row.find_all('td')\n",
    "                movie_info_clean = HTML_table_row_to_dict(table_row_data)\n",
    "                \n",
    "                if type(movie_info_clean) == dict:\n",
    "                    movies_log.append(movie_info_clean)\n",
    "\n",
    "                else:\n",
    "        #             (counter, movie_info_clean[2]['Title'],len(movie_info_clean[2]),list(movie_info_clean[2])[-1])\n",
    "#                     print(movie_info_clean)\n",
    "                    movie_info_clean[1]['Counter'] = counter\n",
    "                    movie_info_clean[1]['Error Message'] = movie_info_clean[0]\n",
    "                    error_log.append(movie_info_clean[1])\n",
    "                counter += 1\n",
    "                \n",
    "        all_movies_clean[year] = movies_log\n",
    "        all_errors_clean[year] = error_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_pickle(filename, var):\n",
    "    \"\"\"\n",
    "    Write the given variable's contents to a pickle file with provided filename\n",
    "    \"\"\"\n",
    "    \n",
    "    with open(filename,'wb') as to_write:\n",
    "        pickle.dump(var,to_write)\n",
    "        \n",
    "def read_from_pickle(filename):\n",
    "    \"\"\"\n",
    "    Read & return data from the given pickle filename\n",
    "    \"\"\"\n",
    "    \n",
    "#     with open(filename,'rb') as to_read:\n",
    "#         var = pickle.load(to_read)\n",
    "#     return var\n",
    "    with open(filename, \"rb\") as f:\n",
    "        unpickler = pickle.Unpickler(f)\n",
    "        # if file is not empty scores will be equal\n",
    "        # to the value unpickled\n",
    "        scores = unpickler.load()\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_movie_list_opening_weekend(year):\n",
    "    \"\"\"\n",
    "    Scrapes the list of movies present in a table format in Box Office Mojo\n",
    "    Checks if the required table data was retrieved from the website\n",
    "    Returns the parsed HTML text for the table portion\n",
    "    \n",
    "    Input: Year\n",
    "    Output: Tuple containing True or False. \n",
    "            if True, returns table rows in HTML format containing movie list.\n",
    "            if False, returns Error message or reason for False\n",
    "    \"\"\"\n",
    "     \n",
    "    url = \"https://www.boxofficemojo.com/year/{}/?sort=openingWeekendGross&grossesOption=totalGrosses\"\n",
    "\n",
    "# Gets data from Box Office Mojo. Checks if status code is not 200. If not 200, returns status code & False\n",
    "# If status code 200, parses the text & looks for table, table row & movie title in second row, to confirm\n",
    "# formatting is similar. If not, returns the same, else errors out.\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url.format(year))\n",
    "        if response.status_code != 200:\n",
    "            return (False, \"For year {} Got status code: {}\".format(year,response.status_code))\n",
    "        \n",
    "        else:\n",
    "            soup = BeautifulSoup(response.text, 'html5lib')\n",
    "            \n",
    "            try:\n",
    "                movie_title = soup.find('div', id='table').find('tbody').find_all('tr')[1].find_all('td')[1].text\n",
    "                if movie_title:\n",
    "                    return (True, soup.find('div', id='table').find('tbody').find_all('tr')[1:])\n",
    "                else:\n",
    "                    return (False, \"No movie title in second <tr> row. Different HTML formatting\")\n",
    "            except Exception as error_message:\n",
    "                return (False, \"Retrieving table/movie title gave following exception: {}\".format(error_message))\n",
    "            \n",
    "    except Exception as error_message:\n",
    "        return (False, \"Error Somewhere in entire block with message: {}\".format(error_message))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HTML_table_row_to_dict(table_row_data):\n",
    "    \"\"\"\n",
    "    Takes in table_row_data for a single table row in HTML syntax for Box Office Mojo \n",
    "    and returns a dictionary with necessary values \n",
    "    \"\"\"\n",
    "    \n",
    "    temp_dict = dict()\n",
    "    try:\n",
    "\n",
    "        temp_dict['Release Link'] = \"https://www.boxofficemojo.com/\"+table_row_data[1].find('a').get('href')\n",
    "        temp_dict['Title'] = table_row_data[1].text\n",
    "        temp_dict['Domestic Gross'] = currency_to_int(table_row_data[5].text)\n",
    "        temp_dict['Max Theatres'] = table_row_data[6].text.strip().replace(',','')\n",
    "        temp_dict['Opening Weekend Gross'] = currency_to_int(table_row_data[7].text)\n",
    "        temp_dict['Domestic to Opening Gross'] = percent_to_float(table_row_data[8].text)\n",
    "        temp_dict['Opening Weekend Theatres'] = table_row_data[9].text.strip().replace(',','')\n",
    "        temp_dict['Release Date'] = table_row_data[10].text + \" \"+str(year)\n",
    "        temp_dict['Studio Link'] = table_row_data[12].find('a').get('href')\n",
    "        temp_dict['Studio Name'] = table_row_data[12].text.strip()\n",
    "    except Exception as ex:\n",
    "        return (ex, temp_dict)\n",
    "\n",
    "    return temp_dict\n",
    "\n",
    "\n",
    "def currency_to_int(amount):\n",
    "    \"\"\"\n",
    "    Converts a given curreny string to an integer\n",
    "    \n",
    "    Input: amount --> '$123,562,324'\n",
    "    Output: Output --> 123562324\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(amount.strip('$').replace(',',''))\n",
    "    except :\n",
    "        return 0\n",
    "\n",
    "def percent_to_float(percentage):\n",
    "    \"\"\"\n",
    "    Converts a given string percentage to float\n",
    "    \n",
    "    Input: 90.4%\n",
    "    Ouput: 0.904\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        return float(percentage.strip('%-'))/100\n",
    "    except:\n",
    "        return 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NOT SURE IF I WILL NEED THE BELOW FUNCTION as a FUNCTION\n",
    "\n",
    "\n",
    "def scrape_movies_list(start_year,end_year):\n",
    "    \"\"\"\n",
    "    Scrapes the movies list from box office mojo and returns the relevant info in HTML format\n",
    "    \n",
    "    Input: Start Year --> eg: 2010\n",
    "           End Year --> eg: 2019\n",
    "    Output: Dictionary with keys for each year & value containing HTML format of all movie table rows\"\"\"\n",
    "    for year in range(start_year,end_year+1,1):\n",
    "        continue\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Testing Code\n",
    "# Delete in the end\n",
    "\n",
    "soup = BeautifulSoup(response.text, 'html5lib')\n",
    "all_tr = soup.find('div', id='table').find('tbody').find_all('tr')\n",
    "all_tr[1].find_all('td')[1].text\n",
    "\n",
    "movies_2020 = list()\n",
    "error_log = list()\n",
    "counter = 1\n",
    "\n",
    "for table_row in all_tr:\n",
    "    \n",
    "    if table_row.find('td'):\n",
    "        \n",
    "        table_row_data = table_row.find_all('td')\n",
    "        \n",
    "        movie_info_clean = HTML_table_row_to_dict(table_row_data)\n",
    "        if type(movie_info_clean) == dict:\n",
    "            movies_2020.append([movie_info_clean])\n",
    "            \n",
    "        else:\n",
    "#             (counter, movie_info_clean[2]['Title'],len(movie_info_clean[2]),list(movie_info_clean[2])[-1])\n",
    "            movie_info_clean[1]['Counter'] = counter\n",
    "            movie_info_clean[1]['Error Message'] = movie_info_clean[0]\n",
    "            error_log.append([movie_info_clean[1]])\n",
    "        counter += 1\n",
    "\n",
    "all_tr[210].find_all('td')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
